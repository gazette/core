#!/usr/bin/env bash

function configure_environment {
  readonly CONTEXT="${1?missing CONTEXT}"

  # DOCKER defaults to `docker`.
  readonly DOCKER="${DOCKER:-docker}"
  # KUBECTL defaults to `kubectl`, and uses an explicit --context.
  readonly KUBECTL="${KUBECTL:-kubectl} --context ${CONTEXT}"
  # HELM defaults to `helm`, and uses an explicit --kube-context and --kubeconfig.
  # KUBECTL may use a non-standard location for its config (eg, microk8s.kubectl
  # manages kubernetes config under its /snap directory). We make configuration
  # explicit by copying into a tempfile and then passing to helm by flag.
  readonly TMPKUBECONFIG=$(mktemp)
  readonly HELM="${HELM:-helm} --kube-context ${CONTEXT} --kubeconfig ${TMPKUBECONFIG}"
  # Fill in TMPKUBECONFIG, and arrange for its removal on exit.
  ${KUBECTL} config view --raw > ${TMPKUBECONFIG}
  trap "{ rm -f ${TMPKUBECONFIG}; }" EXIT
}

# helm_release retrieves the name (eg, "oily-wombat") created by the last
# `helm install` in the specified namespace of the specified Chart.
function helm_release {
  declare -r namespace="${1?missing namespace}"
  declare -r chart="${2?missing chart name}"

  ${HELM} list --date --reverse --namespace ${namespace} --output json | \
    jq -r '.Releases | map(select(.Chart | test("'${chart}'")))[0].Name'
}

# release_address returns the endpoint (eg, "http://172.12.0.10:8080") of the named service
# within the named release. Endpoints are raw IPs, and must have access to the Kubernetes
# network namespace, but do not require access to kube-DNS (eg can be run on the Linux host,
# or a docker container).
#
# release_address requires that Services are using Kubernetes recommended labels:
#   https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/
# Note that Gazette, and many public Helm charts do so, but not all (particularly charts
# generated prior to Helm V2).
function release_address {
  declare -r instance="${1?missing release instance name}"
  declare -r svc="${2?missing service name}"

  host=$(${KUBECTL} --all-namespaces=true get svc -l app.kubernetes.io/instance=${instance} -l app.kubernetes.io/name=${svc} -o "jsonpath={.items[0].spec.clusterIP}")
  port=$(${KUBECTL} --all-namespaces=true get svc -l app.kubernetes.io/instance=${instance} -l app.kubernetes.io/name=${svc} -o "jsonpath={.items[0].spec.ports[0].port}")
  echo "http://${host}:${port}"
}

# install_zonemap installs a gazette-zonemap ConfigMap which contains a
# `node-zone.sh` script. When invoked with a Node name, it outputs a random
# selection of zone-A or zone-B. This simulates multi-zone deployments in
# small or single-node Kubernetes clusters.
function install_zonemap {
  declare -r namespace="${1?missing namespace}"

  # Installing the ConfigMap will fail if the namespace doesn't yet exist.
  ${KUBECTL} create namespace ${namespace} 2> /dev/null || true

  ${KUBECTL} --namespace ${namespace} apply -f - <<EOF
kind: ConfigMap
apiVersion: v1
metadata:
  name: gazette-zonemap
data:
  node-zone.sh: |
    #!/bin/sh
    # This file was generated by v2/test/lib.sh. Do not edit by hand.
    shuf -n 1 << EOF
    zone-A
    zone-B
    EOF
EOF
}
